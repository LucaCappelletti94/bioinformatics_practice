{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import silence_tensorflow.auto\n",
    "from epigenomic_dataset import load_epigenomes\n",
    "from epigenomic_dataset import active_enhancers_vs_inactive_enhancers, \n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "from cache_decorator import Cache\n",
    "from tqdm.keras import TqdmCallback\n",
    "from barplots import barplots\n",
    "from ucsc_genomes_downloader import Genome\n",
    "from keras_bed_sequence import BedSequence\n",
    "from keras_mixed_sequence import MixedSequence, VectorSequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data retrieval\n",
    "First, we retrieve the data and impute and scale them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading chromosomes for genome hg38:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "genome = Genome(\"hg38\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_line = \"K562\"\n",
    "\n",
    "X, y = active_enhancers_vs_inactive_enhancers(\n",
    "    cell_line=cell_line,\n",
    ")\n",
    "\n",
    "X = X.reset_index()\n",
    "bed = X[X.columns[:5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_sequence(\n",
    "    X: pd.DataFrame,\n",
    "    y: np.ndarray,\n",
    "    genome: Genome,\n",
    "    batch_size: int\n",
    ") -> MixedSequence:\n",
    "    return MixedSequence(\n",
    "        x=BedSequence(\n",
    "            genome,\n",
    "            X,\n",
    "            batch_size=batch_size,\n",
    "        ),\n",
    "        y=VectorSequence(\n",
    "            y,\n",
    "            batch_size=batch_size\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mixed_sequence = build_sequence(bed, y[cell_line].values, genome, 1024)\n",
    "inputs, outputs = list(zip(*mixed_sequence))\n",
    "inputs = np.vstack(inputs)\n",
    "outputs = np.hstack(outputs)\n",
    "inputs = inputs.reshape(-1, 256*4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation\n",
    "In order to evaluate the model, we create a generator of **stratified** holdouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "number_of_splits = 10\n",
    "\n",
    "holdouts_generator = StratifiedShuffleSplit(\n",
    "    n_splits=number_of_splits,\n",
    "    test_size=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Dense, Input, Conv2D, Reshape, Flatten, MaxPool2D, Dropout\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from extra_keras_metrics import get_standard_binary_metrics\n",
    "\n",
    "@Cache(\n",
    "    cache_path=[\n",
    "        \"active_enhancers_performance/{function_name}/history_{_hash}.csv.xz\",\n",
    "        \"active_enhancers_performance/{function_name}/performance_{_hash}.csv.xz\",\n",
    "    ],\n",
    "    args_to_ignore=[\n",
    "        \"X_train\", \"X_test\", \"y_train\", \"y_test\", \"genome\"\n",
    "    ]\n",
    ")\n",
    "def train_cnn(\n",
    "    X_train: pd.DataFrame,\n",
    "    X_test: pd.DataFrame,\n",
    "    y_train: np.ndarray,\n",
    "    y_test: np.ndarray,\n",
    "    genome: Genome,\n",
    "    batch_size: int,\n",
    "    holdout_number: int\n",
    ") -> Dict[str, float]:\n",
    "    \"\"\"Return performance of a FFNN.\n",
    "    \n",
    "    Parameters\n",
    "    ----------------------\n",
    "    X_train: pd.DataFrame,\n",
    "        Data reserved for the input during training of the model.\n",
    "    X_test: pd.DataFrame,\n",
    "        Data reserved for the input during  test of the model.\n",
    "    y_train: np.ndarray,\n",
    "        Data reserved for the output during  training of the model.\n",
    "    y_test: np.ndarray,\n",
    "        Data reserved for the output during  test of the model.\n",
    "    genome: Genome,\n",
    "        The genome object to use.\n",
    "    holdout_number: int,\n",
    "        Number of the holdout.\n",
    "        \n",
    "    Returns\n",
    "    ----------------------\n",
    "    Dictionary with the model perfomance.\n",
    "    \"\"\"\n",
    "    train_sequence = build_sequence(X_train, y_train, genome, batch_size=batch_size)\n",
    "    test_sequence = build_sequence(X_test, y_test, genome, batch_size=batch_size)\n",
    "    \n",
    "    cnn = Sequential([\n",
    "        Input((256, 4)),\n",
    "        Reshape((256, 4, 1)),\n",
    "        Conv2D(64, kernel_size=(6, 2), activation=\"relu\", padding=\"same\"),\n",
    "        Conv2D(64, kernel_size=(6, 2), activation=\"relu\", padding=\"same\"),\n",
    "        MaxPool2D((32, 2)),\n",
    "        Flatten(),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(64, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dropout(0.3),\n",
    "        Dense(32, activation=\"relu\"),\n",
    "        Dense(1, activation=\"sigmoid\")\n",
    "    ])\n",
    "    cnn.compile(\n",
    "        loss=\"binary_crossentropy\",\n",
    "        optimizer=\"nadam\",\n",
    "        metrics=get_standard_binary_metrics()\n",
    "    )\n",
    "    \n",
    "    cnn.summary()\n",
    "    \n",
    "    history = pd.DataFrame(cnn.fit(\n",
    "        train_sequence,\n",
    "        validation_data=test_sequence,\n",
    "        epochs=1000,\n",
    "        verbose=False,\n",
    "        callbacks=[\n",
    "            EarlyStopping(\"loss\"),\n",
    "            # I have commented this because we do not need this loading bar\n",
    "            # when running the main experiment loop. When you experiment with\n",
    "            # the model structure you may want to enable this to get a feel\n",
    "            # of how the model is performing during the training.\n",
    "            TqdmCallback(verbose=1)\n",
    "        ]\n",
    "    ).history)\n",
    "    \n",
    "    train_evaluation = dict(zip(cnn.metrics_names, cnn.evaluate(train_sequence, verbose=False)))\n",
    "    test_evaluation = dict(zip(cnn.metrics_names, cnn.evaluate(test_sequence, verbose=False)))\n",
    "    train_evaluation[\"run_type\"] = \"train\"\n",
    "    test_evaluation[\"run_type\"] = \"test\"\n",
    "    for evaluation in (train_evaluation, test_evaluation):\n",
    "        evaluation[\"model_name\"] = \"CNN\"\n",
    "        evaluation[\"holdout_number\"] = holdout_number\n",
    "    \n",
    "    evaluations = pd.DataFrame([\n",
    "        train_evaluation,\n",
    "        test_evaluation\n",
    "    ])\n",
    "    \n",
    "    return history, evaluations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finally we create the main loop!\n",
    "Now we can put everything togheter and run our experiment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store all the computed performance\n",
    "all_performance = []\n",
    "\n",
    "# Start the main loop, iterating through the holdouts\n",
    "for holdout_number, (train_indices, test_indices) in tqdm(\n",
    "    enumerate(holdouts_generator.split(bed, y)),\n",
    "    total=number_of_splits,\n",
    "    desc=\"Computing holdouts\"\n",
    "):\n",
    "    X_train, X_test = bed.iloc[train_indices], bed.iloc[test_indices]\n",
    "    y_train, y_test = y.iloc[train_indices], y.iloc[test_indices]\n",
    "    # We compute the model performance\n",
    "    history, performance = train_cnn(\n",
    "        X_train, X_test, y_train.values, y_test.values,\n",
    "        genome,\n",
    "        batch_size=1024,\n",
    "        holdout_number=holdout_number\n",
    "    )\n",
    "    # We chain the computed performance to the performance list\n",
    "    all_performance.append(performance)\n",
    "    break\n",
    "    \n",
    "# We convert the computed performance list into a DataFrame\n",
    "all_performance = pd.concat(all_performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plot_keras_history import plot_history\n",
    "\n",
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
