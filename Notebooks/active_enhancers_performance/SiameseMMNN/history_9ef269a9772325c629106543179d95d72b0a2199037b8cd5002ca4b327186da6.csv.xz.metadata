{
    "creation_time": 1619180249.6178918,
    "creation_time_human": "2021-04-23 12:17:29",
    "time_delta": 19.32106304168701,
    "time_delta_human": "19 seconds",
    "file_dump_time": 0.018477678298950195,
    "file_dump_time_human": "0 seconds",
    "file_dump_size": 728,
    "file_dump_size_human": "728 Bytes",
    "load_kwargs": {},
    "dump_kwargs": {},
    "function_name": "train_model",
    "function_file": "<ipython-input-9-53e2a4543059>:3",
    "args_to_ignore": [
        "model",
        "training_sequence",
        "test_sequence"
    ],
    "source": "@Cache(\n    cache_path=[\n        \"active_enhancers_performance/{model_name}/history_{_hash}.csv.xz\",\n        \"active_enhancers_performance/{model_name}/performance_{_hash}.csv.xz\",\n    ],\n    args_to_ignore=[\n        \"model\", \"training_sequence\", \"test_sequence\"\n    ]\n)\ndef train_model(\n    model:Model,\n    model_name: str,\n    training_sequence:MixedSequence,\n    test_sequence:MixedSequence,\n    holdout_number: int\n):\n    history = pd.DataFrame(model.fit(\n        train_sequence,\n        validation_data=test_sequence,\n        epochs=1000,\n        verbose=False,\n        callbacks=[\n            EarlyStopping(\"loss\"),\n            # I have commented this because we do not need this loading bar\n            # when running the main experiment loop. When you experiment with\n            # the model structure you may want to enable this to get a feel\n            # of how the model is performing during the training.\n            TqdmCallback(verbose=1)\n        ]\n    ).history)\n    \n    train_evaluation = dict(zip(model.metrics_names, model.evaluate(train_sequence, verbose=False)))\n    test_evaluation = dict(zip(model.metrics_names, model.evaluate(test_sequence, verbose=False)))\n    train_evaluation[\"run_type\"] = \"train\"\n    test_evaluation[\"run_type\"] = \"test\"\n    for evaluation in (train_evaluation, test_evaluation):\n        evaluation[\"model_name\"] = model_name\n        evaluation[\"holdout_number\"] = holdout_number\n    \n    evaluations = pd.DataFrame([\n        train_evaluation,\n        test_evaluation\n    ])\n    \n    return history, evaluations\n",
    "backend_metadata": {
        "type": "pandas",
        "columns_types": {
            "loss": "float64",
            "accuracy": "float64",
            "recall": "float64",
            "precision": "float64",
            "AUROC": "float64",
            "AUPRC": "float64",
            "f1_score": "float64",
            "balanced_accuracy": "float64",
            "specificity": "float64",
            "miss_rate": "float64",
            "fall_out": "float64",
            "mcc": "float64",
            "tp/t": "float64",
            "fp/t": "float64",
            "tn/t": "float64",
            "fn/t": "float64",
            "negative_predictive_value": "float64",
            "false_discovery_rate": "float64",
            "false_omission_rate": "float64",
            "prevalence_threshold": "float64",
            "threat_score": "float64",
            "fowlkes_mallows_index": "float64",
            "informedness": "float64",
            "markedness": "float64",
            "LR_pos": "float64",
            "LR_neg": "float64",
            "DOR": "float64",
            "val_loss": "float64",
            "val_accuracy": "float64",
            "val_recall": "float64",
            "val_precision": "float64",
            "val_AUROC": "float64",
            "val_AUPRC": "float64",
            "val_f1_score": "float64",
            "val_balanced_accuracy": "float64",
            "val_specificity": "float64",
            "val_miss_rate": "float64",
            "val_fall_out": "float64",
            "val_mcc": "float64",
            "val_tp/t": "float64",
            "val_fp/t": "float64",
            "val_tn/t": "float64",
            "val_fn/t": "float64",
            "val_negative_predictive_value": "float64",
            "val_false_discovery_rate": "float64",
            "val_false_omission_rate": "float64",
            "val_prevalence_threshold": "float64",
            "val_threat_score": "float64",
            "val_fowlkes_mallows_index": "float64",
            "val_informedness": "float64",
            "val_markedness": "float64",
            "val_LR_pos": "float64",
            "val_LR_neg": "float64",
            "val_DOR": "float64"
        },
        "index_type": "int64",
        "columns_names_type": "str"
    },
    "parameters": {
        "model_name": "SiameseMMNN",
        "holdout_number": 0
    }
}