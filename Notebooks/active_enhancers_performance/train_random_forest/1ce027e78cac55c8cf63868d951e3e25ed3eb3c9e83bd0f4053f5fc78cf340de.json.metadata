{
    "creation_time": 1618346549.0536292,
    "creation_time_human": "2021-04-13 20:42:29",
    "time_delta": 19.852102279663086,
    "time_delta_human": "19 seconds",
    "file_dump_time": 0.0003814697265625,
    "file_dump_time_human": "0 seconds",
    "file_dump_size": 391,
    "file_dump_size_human": "391 Bytes",
    "load_kwargs": {},
    "dump_kwargs": {},
    "function_name": "train_random_forest",
    "function_file": "<ipython-input-8-cfda08230b33>:5",
    "args_to_ignore": [
        "X_train",
        "X_test",
        "y_train",
        "y_test"
    ],
    "source": "@Cache(\n    cache_path=\"active_enhancers_performance/{function_name}/{_hash}.json\",\n    args_to_ignore=[\n        \"X_train\", \"X_test\", \"y_train\", \"y_test\"\n    ]\n)\ndef train_random_forest(\n    X_train: np.ndarray,\n    X_test: np.ndarray,\n    y_train: np.ndarray,\n    y_test: np.ndarray,\n    holdout_number: int,\n    use_feature_selection: bool\n) -> Dict[str, float]:\n    \"\"\"Return performance of a Random Forest model.\n    \n    Parameters\n    ----------------------\n    X_train: np.ndarray,\n        Data reserved for the input during training of the model.\n    X_test: np.ndarray,\n        Data reserved for the input during  test of the model.\n    y_train: np.ndarray,\n        Data reserved for the output during  training of the model.\n    y_test: np.ndarray,\n        Data reserved for the output during  test of the model.\n    holdout_number: int,\n        Number of the holdout.\n    use_feature_selection: bool,\n        Whether the model is trained using features that have\n        been selected with Boruta or not.\n        \n    Returns\n    ----------------------\n    Dictionary with the model perfomance.\n    \"\"\"\n    forest = RandomForestClassifier(\n        n_estimators=600,\n        class_weight=\"balanced_subsample\",\n        max_depth=5,\n        min_samples_leaf=100,\n        n_jobs=cpu_count(),\n        verbose=False\n    )\n    forest.fit(X_train, y_train)\n    y_train_pred = forest.predict(X_train)\n    y_test_pred = forest.predict(X_test)\n    return evaluate_all_model_prediction(\n        y_train, y_train_pred, y_test, y_test_pred,\n        \"Random Forest\", holdout_number, use_feature_selection\n    )\n",
    "backend_metadata": {},
    "parameters": {
        "holdout_number": 5,
        "use_feature_selection": true
    }
}